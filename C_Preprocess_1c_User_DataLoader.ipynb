{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C_Preprocess_1c_User_DataLoader.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1vbb3hNVCzkp7GmozYHoN0KV6ucOZ1wva","authorship_tag":"ABX9TyPWcDUC5e8Ifpvj2KESfipO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vC7t8rNEMoP7"},"source":["# Data loader\n","12 users geo-spatial and kinematic features"]},{"cell_type":"markdown","metadata":{"id":"nXDtFV9PZWRq"},"source":["## Load libraries"]},{"cell_type":"code","metadata":{"id":"b4HZtp4lMuf_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611132224587,"user_tz":-480,"elapsed":6723,"user":{"displayName":"wind losd","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv1UwF6iyYsR8HrUTU_EeQVVPzfG82wFATtXqtZSU=s64","userId":"05841662885873618484"}},"outputId":"9f26b0c9-cf71-4f10-f5bb-2217fd593be1"},"source":["# use SWAG\n","!pip install torchcontrib\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torchcontrib\n","  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n","Building wheels for collected packages: torchcontrib\n","  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp36-none-any.whl size=7531 sha256=addf5de478747c7dcbf9c966c767e5a213a90110ffd3b0dee1e2a8a692d947e1\n","  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n","Successfully built torchcontrib\n","Installing collected packages: torchcontrib\n","Successfully installed torchcontrib-0.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pGNnL9OnMoP9"},"source":["%load_ext autoreload\n","%autoreload 2\n","import os\n","import sys\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchcontrib.optim import SWA     # use SWAG\n","from torch.autograd import Variable\n","from collections import OrderedDict\n","torch.manual_seed(1) # 设置随机种子，保证可重复性\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 设置使用CPU or GPU\n","\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn.model_selection import KFold\n","\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc\n","from sklearn.metrics import recall_score,precision_score,f1_score\n","\n","from sklearn.preprocessing import label_binarize\n","from scipy import interp\n","from itertools import cycle\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n","matplotlib.rcParams['figure.figsize'] = [10, 10] # for square canvas\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlolJ9WR3W1g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611132230627,"user_tz":-480,"elapsed":12613,"user":{"displayName":"wind losd","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv1UwF6iyYsR8HrUTU_EeQVVPzfG82wFATtXqtZSU=s64","userId":"05841662885873618484"}},"outputId":"018ad133-820f-47d1-f82d-17dc97fe9404"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","!pip install GPUtil\n","\n","def check_GPU():\n","    gpu_info = !nvidia-smi\n","    gpu_info = '\\n'.join(gpu_info)\n","    if gpu_info.find('failed') >= 0: \n","        print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","        print('and then re-execute this cell.')\n","    else:\n","        print(gpu_info)\n","\n","    from psutil import virtual_memory\n","    ram_gb = virtual_memory().total / 1e9\n","    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","    if ram_gb < 20:\n","        print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","        print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","        print('re-execute this cell.')\n","    else:\n","        print('You are using a high-RAM runtime!')\n","\n","# Import packages\n","\n","import os,sys,humanize,psutil,GPUtil\n","\n","# Define function\n","def mem_report():\n","  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n","  \n","  GPUs = GPUtil.getGPUs()\n","  for i, gpu in enumerate(GPUs):\n","    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n","    \n","# Execute function\n","\n","mem_report()\n","check_GPU()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting GPUtil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=f42ed613a1f6be4e35b15d82d882de05318255c6f5da84c9504c46e18619aceb\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n","CPU RAM Free: 26.2 GB\n","GPU 0 ... Mem Free: 16120MB / 16130MB | Utilization   0%\n","Wed Jan 20 08:43:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    26W / 300W |     10MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.4 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ogxQ07f1ZaiD"},"source":["#### Check whether the folder is already present before download and unzip"]},{"cell_type":"code","metadata":{"id":"Cg7MZ0wPWB05"},"source":["working_path = '/content/drive/My Drive/s182190/data'\n","try:\n","  os.chdir(f'{working_path}')\n","except:\n","  print('Download and unzip folder')\n","  !wget https://staticavantipw.s3.eu-west-1.amazonaws.com/DeepLearning2020data/MMM_DataLoaderForStudentsC.zip\n","  !unzip '/content/MMM_DataLoaderForStudentsC.zip' -d '/content/drive/My Drive/'\n","\n","# sys.path.append(f'{working_path}/src')\n","# print(sys.path)\n","from data_utils_conda import *\n","clear_output(wait=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l5CXiPeEMoQH"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"_njPYozb8Z9Q"},"source":["dataset = pd.read_pickle(f'{working_path}/processed/dataset_merged.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NEsUDrLpcKSG"},"source":["### Load GPS+GIS fusion tensors - dimensionality 9x9x11 - ( [see explaination here](https://www.sciencedirect.com/science/article/pii/S0968090X20307385?dgcid=author#bfn4))\n","\n","Remember to delete \"image_data\" after training, before loading \"image_data\" with the user_test partition, so that the dataloader can perform the test on your network, with weights and biases resulting from the training."]},{"cell_type":"code","metadata":{"id":"1MrljkjiMoQQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611132485220,"user_tz":-480,"elapsed":267198,"user":{"displayName":"wind losd","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv1UwF6iyYsR8HrUTU_EeQVVPzfG82wFATtXqtZSU=s64","userId":"05841662885873618484"}},"outputId":"c4b42052-d0ea-43a9-cdb7-c09612490927"},"source":["image_data = pd.read_pickle(f'{working_path}/processed/image_data.pkl')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["User 1, image shape (17990, 9, 9, 11)\n","User 2, image shape (20132, 9, 9, 11)\n","User 3, image shape (83326, 9, 9, 11)\n","User 4, image shape (667160, 9, 9, 11)\n","User 5, image shape (14112, 9, 9, 11)\n","User 6, image shape (2344, 9, 9, 11)\n","User 7, image shape (22616, 9, 9, 11)\n","User 9, image shape (425710, 9, 9, 11)\n","User 10, image shape (86277, 9, 9, 11)\n","User 11, image shape (28845, 9, 9, 11)\n","User 12, image shape (117610, 9, 9, 11)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S_abdcAxbiG9"},"source":["## Create train validation and test partitions"]},{"cell_type":"markdown","metadata":{"id":"qqnjue4hrXOJ"},"source":["Since user 4 and 9 have lots of points, We use k parameter to define a specific slice of the train, validation and test collection. If you want to learn more, please go to the data utilis.py. \n","\n","For the formal test later of the algorithm, the -random- parameter is set to be True, k is not invoked."]},{"cell_type":"code","metadata":{"id":"U9fS6i2gMoQE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611132485854,"user_tz":-480,"elapsed":267824,"user":{"displayName":"wind losd","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv1UwF6iyYsR8HrUTU_EeQVVPzfG82wFATtXqtZSU=s64","userId":"05841662885873618484"}},"outputId":"80c612b9-5856-47b8-d02d-4cbe57a0901c"},"source":["user_train, user_val, user_test = train, val, test = train_test_data_split(dataset.user.unique(),Random=False, k = 9) # use specified splits, check the source code\n","print(f'partition: train {user_train}, validation {user_val}, test {user_test}')\n","\n","data_train =  pd.concat([dataset[(dataset.user==tr)] for tr in user_train]).reset_index(drop=True)\n","data_val = pd.concat([dataset[(dataset.user==va)] for va in user_val]).reset_index(drop=True)\n","data_test = pd.concat([dataset[(dataset.user==te)] for te in user_test]).reset_index(drop=True)\n","\n","print(f'length: train {len(data_train)}, validation {len(data_val)}, test {len(data_test)}')\n","\n","data_train.head(10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["partition: train [4, 1, 8, 12, 11, 7, 10, 5], validation [9], test [3, 2, 6]\n","length: train 585391, validation 200669, test 62031\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>ts</th>\n","      <th>image_ix</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>x_web</th>\n","      <th>y_web</th>\n","      <th>label2</th>\n","      <th>labelP</th>\n","      <th>labelM</th>\n","      <th>delta_t</th>\n","      <th>delta_d</th>\n","      <th>bearing</th>\n","      <th>speed</th>\n","      <th>tod</th>\n","      <th>segment_id</th>\n","      <th>segment_ix</th>\n","      <th>segment_point_count</th>\n","      <th>mode</th>\n","      <th>purpose</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>2018-06-15-05</td>\n","      <td>3</td>\n","      <td>1.405763e+06</td>\n","      <td>7.485806e+06</td>\n","      <td>1.405763e+06</td>\n","      <td>7.485806e+06</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>126.0</td>\n","      <td>167.688110</td>\n","      <td>-1.169201</td>\n","      <td>1.330858</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Light Rail</td>\n","      <td>-100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3684</td>\n","      <td>1.394213e+06</td>\n","      <td>7.516659e+06</td>\n","      <td>1.394213e+06</td>\n","      <td>7.516659e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>2139.0</td>\n","      <td>6.735206</td>\n","      <td>1.248921</td>\n","      <td>0.003149</td>\n","      <td>1</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3685</td>\n","      <td>1.394209e+06</td>\n","      <td>7.516648e+06</td>\n","      <td>1.394209e+06</td>\n","      <td>7.516648e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>10.977184</td>\n","      <td>-1.906872</td>\n","      <td>0.645717</td>\n","      <td>1</td>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3688</td>\n","      <td>1.394214e+06</td>\n","      <td>7.516664e+06</td>\n","      <td>1.394214e+06</td>\n","      <td>7.516664e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>82.0</td>\n","      <td>16.436425</td>\n","      <td>1.248127</td>\n","      <td>0.200444</td>\n","      <td>1</td>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3689</td>\n","      <td>1.394213e+06</td>\n","      <td>7.516659e+06</td>\n","      <td>1.394213e+06</td>\n","      <td>7.516659e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>41.0</td>\n","      <td>5.115697</td>\n","      <td>-1.864637</td>\n","      <td>0.124773</td>\n","      <td>1</td>\n","      <td>30</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3692</td>\n","      <td>1.394216e+06</td>\n","      <td>7.516667e+06</td>\n","      <td>1.394216e+06</td>\n","      <td>7.516667e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>103.0</td>\n","      <td>8.163831</td>\n","      <td>1.237253</td>\n","      <td>0.079260</td>\n","      <td>1</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3693</td>\n","      <td>1.394215e+06</td>\n","      <td>7.516665e+06</td>\n","      <td>1.394215e+06</td>\n","      <td>7.516665e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>756.0</td>\n","      <td>2.301488</td>\n","      <td>-1.928052</td>\n","      <td>0.003044</td>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3694</td>\n","      <td>1.394213e+06</td>\n","      <td>7.516659e+06</td>\n","      <td>1.394213e+06</td>\n","      <td>7.516659e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>134.0</td>\n","      <td>6.354567</td>\n","      <td>-1.932308</td>\n","      <td>0.047422</td>\n","      <td>1</td>\n","      <td>33</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3696</td>\n","      <td>1.394216e+06</td>\n","      <td>7.516667e+06</td>\n","      <td>1.394216e+06</td>\n","      <td>7.516667e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>114.0</td>\n","      <td>8.325730</td>\n","      <td>1.206465</td>\n","      <td>0.073033</td>\n","      <td>1</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4</td>\n","      <td>2018-06-15-08</td>\n","      <td>3697</td>\n","      <td>1.394216e+06</td>\n","      <td>7.516667e+06</td>\n","      <td>1.394216e+06</td>\n","      <td>7.516667e+06</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>140.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-100</td>\n","      <td>Education</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user             ts  image_ix  ...  segment_point_count        mode    purpose\n","0     4  2018-06-15-05         3  ...                    1  Light Rail       -100\n","1     4  2018-06-15-08      3684  ...                    2        -100  Education\n","2     4  2018-06-15-08      3685  ...                    2        -100  Education\n","3     4  2018-06-15-08      3688  ...                    2        -100  Education\n","4     4  2018-06-15-08      3689  ...                    2        -100  Education\n","5     4  2018-06-15-08      3692  ...                    1        -100  Education\n","6     4  2018-06-15-08      3693  ...                    1        -100  Education\n","7     4  2018-06-15-08      3694  ...                    1        -100  Education\n","8     4  2018-06-15-08      3696  ...                    1        -100  Education\n","9     4  2018-06-15-08      3697  ...                    1        -100  Education\n","\n","[10 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"-j95if8oMoQW"},"source":["### Define Image Tensor Dataloader\n","\n","We implement our own Tensor Dataset in order to be able to do fast lookup of sequences and images. Just add features inside\n","```\n","df[['feat1','feat2',...]]\n","```"]},{"cell_type":"code","metadata":{"id":"PBltgEVeMoQW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611132486424,"user_tz":-480,"elapsed":268394,"user":{"displayName":"wind losd","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjv1UwF6iyYsR8HrUTU_EeQVVPzfG82wFATtXqtZSU=s64","userId":"05841662885873618484"}},"outputId":"7be0e5d2-9b17-4562-a2ba-f51f62a209a2"},"source":["class ImageTensorDataset(torch.utils.data.Dataset):\n","    filter_seq = 5\n","    def __init__(self, df, image_data,filter_seq=filter_seq):\n","        self.seq = np.stack([np.roll(df[['delta_d', 'bearing']].values, i, axis = 0) for i in range(filter_seq, -1, -1)], axis = 1)\n","        self.seq = self.seq[df['segment_ix'] >= filter_seq]\n","\n","        self.label2 = df[df['segment_ix'] >= filter_seq]['label2'].values # need to transfer from 1,2 to 0,1\n","        self.labelM = df[df['segment_ix'] >= filter_seq]['labelM'].values\n","        self.labelP = df[df['segment_ix'] >= filter_seq]['labelP'].values\n","     \n","        self.user_id = df[df['segment_ix'] >= filter_seq]['user'].values\n","        self.image_ix = df[df['segment_ix'] >= filter_seq]['image_ix'].values        \n","        self.image_data = image_data\n","        tod = df[df['segment_ix'] >= filter_seq]['tod'].values\n","        self.tod_one_hot = np.eye(5)[tod]\n","        \n","    def __len__(self):\n","        return len(self.label2)\n","    \n","    def __getitem__(self, key):\n","        image = self.image_data[self.user_id[key]][self.image_ix[key]]\n","        return image, self.seq[key], self.tod_one_hot[key], self.label2[key] - 1, self.labelM[key], self.labelP[key]\n","\n","demo_dataset = ImageTensorDataset(data_train, image_data)\n","demo_loader = torch.utils.data.DataLoader(demo_dataset, batch_size=3, shuffle=True)\n","\n","for X_img, X_seq, X_tod, y1, y2, y3 in demo_loader:\n","    print('X_img :', X_img.shape)\n","    print(X_img[0, :, :, 0])\n","    print('X_seq :', X_seq.shape)\n","    print(X_seq[0, :])\n","    print('X_tod :', X_tod.shape)\n","    print(X_tod[0])\n","    print('y1:', y2.shape)\n","    print(y1[0])\n","    print(y2[0])\n","    print(y3[0])\n","    break;"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_img : torch.Size([3, 9, 9, 11])\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n","X_seq : torch.Size([3, 6, 2])\n","tensor([[0., 0.],\n","        [0., 0.],\n","        [0., 0.],\n","        [0., 0.],\n","        [0., 0.],\n","        [0., 0.]], dtype=torch.float64)\n","X_tod : torch.Size([3, 5])\n","tensor([0., 1., 0., 0., 0.], dtype=torch.float64)\n","y1: torch.Size([3])\n","tensor(0)\n","tensor(0., dtype=torch.float64)\n","tensor(4., dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4rSvIFHwCEcL"},"source":["### define train, val, test set and dataloader"]},{"cell_type":"code","metadata":{"id":"RW01HbMeCDjt"},"source":["    train_dataset = ImageTensorDataset(data_train, image_data)\n","    val_dataset = ImageTensorDataset(data_val, image_data)\n","    test_dataset = ImageTensorDataset(data_test, image_data)"],"execution_count":null,"outputs":[]}]}